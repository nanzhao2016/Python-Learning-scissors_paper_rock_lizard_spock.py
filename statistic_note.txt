Online Statistics Education: An Interactive Multimedia Course of Study
http://onlinestatbook.com/2/index.html


Part1. Introduction

Inferential Statistics
In statistics, we often rely on a sample --- that is, a small subset of a larger set of data --- to draw inferences about the larger set. The larger set is known as the population.

Simple Random Sampling
Such sampling requires every member of the population to have an equal chance of being selected into the sample. 
In addition, the selection of one member must be independent of the selection of every other member. 
That is, picking one member from the population must not increase or decrease the probability of picking any other member (relative to the others). 

Random sampling chooses a sample by pure chance

More Complex Sampling
1. Random Assignment : used for experiment studies: experimental group vs control group, 
Random assignment is critical for the validity of an experiment. 
In experimental research of this kind, failure to assign subjects randomly to groups is generally more serious than having a non-random sample.
Failure to randomize (the former error) invalidates the experimental findings. A non-random sample (the latter error) simply restricts the generalizability of the results.

2. Stratified Sampling: 
In stratified sampling, you first identify members of your sample who belong to each group. 
Then you randomly sample from each of those subgroups in such a way that the sizes of the subgroups in the sample are proportional to their sizes in the population. 

Stratified sampling is more likely to be representative of the population than random sampling.
The only way to eliminate uncertainty is to obtain data from the whole population. You can reduce uncertainty with a large sample.
Using a random sample:
is to accept some uncertainty about the conclusions. 

enables you to calculate statistics. 

is to risk drawing the wrong conclusions about the population. 
 
A biased sample is one that 

will likely have groups from the population over-represented or under-represented due to systematic sampling factors. 
Bias is defined by the procedure for drawing the sample, not by the result.

Levels of Measurement
nominal, ordinal, interval, and ratio scales
ordinal scales fail to capture important informations
In particular, the difference between two levels of an ordinal scale cannot be assumed to be the same as the difference between two other levels.
Statisticians express this point by saying that the differences between adjacent scale values do not necessarily represent equal intervals on the underlying scale giving rise to the measurements.

Interval scales are numerical scales in which intervals have the same interpretation throughout. 
Interval scales are not perfect, however. In particular, they do not have a true zero point even if one of the scaled values happens to carry the name "zero." 
For example, there is no sense in which the ratio of 40 to 20 degrees Fahrenheit is the same as the ratio of 100 to 50 degrees; no interesting physical property is preserved across the two ratios. 
The ratio scale of measurement is the most informative scale. It is an interval scale with the additional property that its zero position indicates the absence of the quantity being measured. 
You can think of a ratio scale as the three earlier scales rolled up in one. Like a nominal scale, it provides a name or category for each object (the numbers serve as labels). 
Like an ordinal scale, the objects are ordered (in terms of the ordering of the numbers). Like an interval scale, the same difference at two places on the scale has the same meaning. 
And in addition, the same ratio at two places on the scale also carries the same meaning.

Rating scales are used frequently in psychological research.
Typically these ratings are made on a 5-point or a 7-point scale. These scales are ordinal scales since there is no assurance that a given difference represents the same thing across the range of the scale. 

Does it make sense to compute the mean of numbers measured on an ordinal scale? This is a difficult question, one that statisticians have debated for decades. 
The prevailing (but by no means unanimous) opinion of statisticians is that for almost all practical situations, the mean of an ordinally-measured variable is a meaningful statistic. 
However, as you will see in the simulation, there are extreme situations in which computing the mean of an ordinally-measured variable can be very misleading.

Ordinal scales preserve the order of the values, but not the differences between values.

http://onlinestatbook.com/2/introduction/measurement_demo.html
A difference between the means of two groups on an ordinal rating scale : 
For all but the most extraordinary situations, differences between means on interval scales are meaningful. 
, in extreme circumstances, it is possible for the difference on an ordinal scale to be in the oppostite direction from the difference on an interval scale.


Distributions
frequency distribution VS probability distribution
Distributions of Discrete Variables

Table 1. Frequencies in the Bag of M&M's
Color	Frequency
Brown	17
Red		18
Yellow	7
Green	7
Blue		2
Orange	4

This table is called a frequency table and it describes the distribution of M&M color frequencies. 
We call Figure 2 a probability distribution because if you choose an M&M at random, the probability of getting, say, a brown M&M is equal to the proportion of M&M's that are brown (0.30).

Chance factors involving the machines used by the manufacturer introduce random variation into the different bags produced. Some bags will have a distribution of colors that is close to Figure 2; 
others will be further away.

Continuous Variables
histogram can be used to show the grouped frequency distribution

Probability Densities (continuous distribution)
normal distribution: The Y-axis in the normal distribution represents the "density of probability." Intuitively, it shows the chance of obtaining values near corresponding points on the X-axis.

the curve that describes a continuous distribution (like the normal distribution). 
First, the area under the curve equals 1. 
Second, the probability of any exact value of X is 0. 
Finally, the area under the curve and bounded between two given points on the X-axis is the probability that a number chosen at random will fall between the two points.

A distribution with two peaks is called a bimodal distribution.
Distributions also differ from each other in terms of how large or "fat" their tails are. 
The upper distribution has relatively more scores in its tails; its shape is called leptokurtic. The lower distribution has relatively fewer scores in its tails; its shape is called platykurtic.


Part2. Graphing Distributions
Graphing Qualitative Variables

Pie charts are effective for displaying the relative frequencies of a small number of categories. 
Pie charts can also be confusing when they are used to compare the outcomes of two different surveys or experiments. 
In an influential book on the use of graphs, Edward Tufte asserted, "The only worse design than a pie chart is several of them."
we note that it is a serious mistake to use a line graph when the X-axis contains merely qualitative variables.

Pie charts and bar charts can both be effective methods of portraying qualitative data. 
Bar charts are better when there are more than just a few categories and for comparing two or more distributions

Quantitative Variables

Stem and Leaf Displays
Whether your data can be suitably represented by a stem and leaf graph depends on whether they can be rounded without loss of important information. 

Histograms

A histogram is a graphical method for displaying the shape of a distribution. It is particularly useful when there are a large number of observations. 

Table 1. Grouped Frequency Distribution of Psychology Test Scores
Interval's Lower Limit	Interval's Upper Limit	Class Frequency
39.5	49.5	3
49.5	59.5	10
59.5	69.5	53
69.5	79.5	107
79.5	89.5	147
89.5	99.5	130
99.5	109.5	78
109.5	119.5	59
119.5	129.5	36
129.5	139.5	11s
139.5	149.5	6
149.5	159.5	1
159.5	169.5	1

the range of scores was broken into intervals, called class intervals,
Class intervals of width 10 provide enough detail about the distribution to be revealing without making the graph too "choppy." 
More information on choosing the widths of class intervals is presented later in this section. 
Placing the limits of the class intervals midway between two numbers (e.g., 49.5) ensures that every score will fall in an interval rather than on the boundary between intervals.
The histogram makes it plain that most of the scores are in the middle of the distribution, with fewer scores in the extremes. 
Using whole numbers as boundaries avoids a cluttered appearance, and is the practice of many computer programs that create histograms. 
Note also that some computer programs label the middle of each interval rather than the end points.
Histograms can be based on relative frequencies instead of actual frequencies. Histograms based on relative frequencies show the proportion of scores in each interval rather than the number of scores. 

widths of the class intervals = bin widths

Your choice of bin width determines the number of class intervals. This decision, along with the choice of starting point for the first interval, affects the shape of the histogram.
Sturges' rule is to set the number of intervals as close as possible to 1 + Log2(N), where Log2(N) is the base 2 log of the number of observations. 
The formula can also be written as 1 + 3.3 Log10(N)
We prefer the Rice rule, which is to set the number of intervals to twice the cube root of the number of observations ******

The best advice is to experiment with different choices of width, and to choose a histogram according to how well it communicates the shape of the distribution.

Frequency Polygons
Frequency polygons are useful for comparing distributions. This is achieved by overlaying the frequency polygons drawn for different data sets. 
Frequency polygons are better at comparing distributions because two frequency polygons can be displayed in the same graph without obscuring each other. 
Both histograms and frequency polygons show the shape of the distribution. Neither necessarily reveals the exact values in a distribution.
Frequency polygons are a graphical device for understanding the shapes of distributions. They serve the same purpose as histograms, but are especially helpful for comparing sets of data.

Boxplot
Since half the scores in a distribution are between the hinges (recall that the hinges are the 25th and 75th percentiles), 
we see that half the women's times are between 17 and 20 seconds, whereas half the men's times are between 19 and 25.5. 
We also see that women generally named the colors faster than the men did, although one woman was slower than almost all of the men.

a distribution with a positive skew would have a longer whisker in the positive direction than in the negative direction. 
A larger mean than median would also indicate a positive skew. Box plots are good at portraying extreme values and are especially good at showing differences between distributions. 
However, many of the details of a distribution are not revealed in a box plot, and to examine these details one should create a histogram and/or a stem and leaf display.


Part3. Summarizing Distributions
Median and Mean

51) the point on which a distribution would balance, (2) the value whose average absolute deviation from all the other values is minimized, and (3) the value whose average squared difference from all the other values is minimized. 
From the simulation in this chapter, you discovered (we hope) that the mean is the point on which a distribution would balance, the median is the value that minimizes the sum of absolute deviations, and the mean is the value that minimizes the sum of the squared deviations.


Additional Measures of Central Tendency
Trimean
The trimean is a weighted average of the 25th percentile, the 50th percentile, and the 75th percentile. Letting P25 be the 25th percentile, P50 be the 50th and P75 be the 75th percentile, the formula for the trimean is:
Trimean = (P25 + 2P50 + P75)/4

Geometric Mean
The geometric mean is computed by multiplying all the numbers together and then taking the nth root of the product.
The geometric mean is an appropriate measure to use for averaging rates. For example, consider a stock portfolio that began with a value of $1,000 and had annual returns of 13%, 22%, 12%, -5%, and -13%. Table 4 shows the value after each of the five years.
Table 4. Portfolio Returns
Year	Return	Value
1	13%	1,130
2	22%	1,379
3	12%	1,544
4	-5%	1,467
5	-13%	1,276
The question is how to compute average annual rate of return. The answer is to compute the geometric mean of the returns. Instead of using the percents, each return is represented as a multiplier indicating how much higher the value is after the year. 
This multiplier is 1.13 for a 13% return and 0.95 for a 5% loss. The multipliers for this example are 1.13, 1.22, 1.12, 0.95, and 0.87. 
The geometric mean of these multipliers is 1.05. Therefore, the average annual rate of return is 5%. Table 5 shows how a portfolio gaining 5% a year would end up with the same value ($1,276) as shown in Table 4.

Trimmed Mean
To compute a trimmed mean, you remove some of the higher and lower scores and compute the mean of the remaining scores. A mean trimmed 10% is a mean computed with 10% of the scores trimmed off: 5% from the bottom and 5% from the top. 
A mean trimmed 50% is computed by trimming the upper 25% of the scores and the lower 25% of the scores and computing the mean of the remaining scores. The trimmed mean is similar to the median which, in essence, trims the upper 49+% and the lower 49+% of the scores. 
Therefore the trimmed mean is a hybrid of the mean and the median. To compute the mean trimmed 20% for the touchdown pass data shown in Table 1, you remove the lower 10% of the scores (6, 9, and 12) as well as the upper 10% of the scores (33, 33, and 37) and compute the mean of the remaining 25 scores. This mean is 20.16.


Fortunately, there is no need to summarize a distribution with a single number. When the various measures differ, our opinion is that you should report the mean, median, and either the trimean or the mean trimmed 50%. 
Sometimes it is worth reporting the mode as well. In the media, the median is usually reported to summarize the center of skewed distributions. 

Measures of Variability

What is Variability?
Variability refers to how "spread out" a group of scores is.
There are four frequently used measures of variability: the range, interquartile range, variance, and standard deviation.
 
Range
The range is the simplest measure of variability to calculate, and one you have probably encountered many times in your life. 
The range is simply the highest score minus the lowest score.
Let’s take a few examples. What is the range of the following group of numbers: 10, 2, 5, 6, 7, 3, 4? 
Well, the highest number is 10, and the lowest number is 2, so 10 - 2 = 8. The range is 8.

Interquartile Range
The interquartile range (IQR) is the range of the middle 50% of the scores in a distribution. It is computed as follows:
IQR = 75th percentile - 25th percentile
Recall that in the discussion of box plots, the 75th percentile was called the upper hinge and the 25th percentile was called the lower hinge.
Using this terminology, the interquartile range is referred to as the H-spread.
 
A related measure of variability is called the semi-interquartile range. The semi-interquartile range is defined simply as the interquartile range divided by 2. 
If a distribution is symmetric, the median plus or minus the semi-interquartile range contains half the scores in the distribution. 

Variance
Variability can also be defined in terms of how close the scores in the distribution are to the middle of the distribution. 
Using the mean as the measure of the middle of the distribution, the variance is defined as the average squared difference of the scores from the mean.
One thing that is important to notice is that the mean deviation from the mean is 0. This will always be the case. 

where σ2 is the variance, μ is the mean, and N is the number of numbers. 
If the variance in a sample is used to estimate the variance in a population, then the previous formula underestimates the variance and the following formula should be used:

N-1 to calculate the variance
where s2 is the estimate of the variance and M is the sample mean. 
Note that M is the mean of a sample taken from a population with a mean of μ. Since, in practice, the variance is usually computed in a sample, this formula is most often used. 

Standard Deviation
The standard deviation is simply the square root of the variance.
he standard deviation is an especially useful measure of variability when the distribution is normal or approximately normal (see Chapter on Normal Distributions) because the proportion of the distribution within a given number of standard deviations from the mean can be calculated. 
For example, 68% of the distribution is within one standard deviation of the mean and approximately 95% of the distribution is within two standard deviations of the mean.
Therefore, if you had a normal distribution with a mean of 50 and a standard deviation of 10, then 68% of the distribution would be between 50 - 10 = 40 and 50 +10 =60. Similarly, about 95% of the distribution would be between 50 - 2 x 10 = 30 and 50 + 2 x 10 = 70. 
The symbol for the population standard deviation is σ; the symbol for an estimate computed in a sample is s. 

Assume you repeatedly sampled 4 numbers from this population with a variance of 2 and, for each sample, estimated the variance using the average squared difference from the sample mean. 
What would the mean of these variance estimates be?
It would approach 1.5 as the number of samples increases to a very large number. 
This is equal to (N-1)/N = .75 times the population variance of 2.

Shapes of Distributions
The relationship between skew and the relative size of the mean and median led the statistician Pearson to propose the following simple and convenient numerical index of skew:

3(mean-median)/σ

Just as there are several measures of central tendency, there is more than one measure of skew. 
Although Pearson's measure is a good one, the following measure is more commonly used. It is sometimes referred to as the third moment about the mean.

sigma[(X-µ)3/σ3]

Kurtosis
The following measure of kurtosis is similar to the definition of skew. 
The value "3" is subtracted to define "no kurtosis" as the kurtosis of a normal distribution. Otherwise, a normal distribution would have a kurtosis of 3.

sigma[(X-µ)4/σ4]-3

Effects of Linear Transformations

To sum up, if a variable X has a mean of μ, a standard deviation of σ, and a variance of σ2, then a new variable Y created using the linear transformation
Y = bX + A

will have a mean of bμ+A, a standard deviation of bσ, and a variance of b2σ2.

In R, calculate trimmed mean: mean(data, trim=percentage)

Notice that the expression for the difference is the same as the formula for the sum.

(σ2)diff = (σ2)M+(σ2)F


More generally, the variance sum law can be written as follows:

(σ2)X+/-Y = (σ2)X+(σ2)Y

which is read: The variance of X plus or minus Y is equal to the variance of X plus the variance of Y.
These formulas for the sum and difference of variables given above only apply when the variables are independent. 


Part4. Describing Bivariate Data

Introduction to Bivariate Data

Bivariate data is data for which there are two variables for each observation. As an example, the following bivariate data show the ages of husbands and wives of 10 married couples.
 
Husband	36	72	37	36	51	50	47	50	37	41
Wife			35	67	33	35	50	46	47	42	36	41

A scatter plot of two variables shows the values of one variable on the Y axis and the values of the other variable on the X axis. 
Scatter plots are well suited for revealing the relationship between two variables.
parabola
A statistical measure of the strength of the relationship between two quantitative variables that takes these factors into account is the subject of the section "Values of Pearson's Correlation."


Values of the Pearson Correlation
The Pearson product-moment correlation coefficient is a measure of the strength of the linear relationship between two variables. 
It is referred to as Pearson's correlation or simply as the correlation coefficient.

The symbol for Pearson's correlation is "ρ" when it is measured in the population and "r" when it is measured in a sample. 
Pearson's r can range from -1 to 1. 
An r of -1 indicates a perfect negative linear relationship between variables, an r of 0 indicates no linear relationship between variables, and an r of 1 indicates a perfect positive linear relationship between variables.

Properties of Pearson's r
Pearson's correlation is symmetric in the sense that the correlation of X with Y is the same as the correlation of Y with X. 
A critical property of Pearson's r is that it is unaffected by linear transformations.
 
This means that multiplying a variable by a constant and/or adding a constant does not change the correlation of that variable with other variables. 

Computing Pearson's r
We begin by computing the mean for X and subtracting this mean from all values of X. The new variable is called "x". 
The variable "y" is computed similarly. The variables x and y are said to be deviation scores because each score is a deviation from the mean.

Before proceeding with the calculations, let's consider why the sum of the xy column reveals the relationship between X and Y. 
If there were no relationship between X and Y, then positive values of x would be just as likely to be paired with negative values of y as with positive values. 
This would make negative values of xy as likely as positive values and the sum would be small.

Pearson's correlation is computed by dividing the sum of the xy column (Σxy) by the square root of the product of the sum of the x2 column (Σx2) and the sum of the y2 column (Σy2). The resulting formula is:

r= Σxy/ sqrt((Σx2)*(Σy2))

An alternative computational formula that avoids the step of computing deviation scores is:

r= (ΣXY - ΣXY/N) / sqrt(ΣX2 - (ΣX)2/N)*sqrt(ΣY2 - (ΣY)2/N)


Variance Sum Law II
Recall that when the variables X and Y are independent, the variance of the sum or difference between X and Y can be written as follows:

(σ2)X+/-Y = (σ2)X+(σ2)Y
==> var(X+/-Y) = var(X) + var(Y) 

which is read: "The variance of X plus or minus Y is equal to the variance of X plus the variance of Y."
When X and Y are correlated, the following formula should be used:

(σ2)X+/-Y = (σ2)X+(σ2)Y +/- 2ρσXσY

where ρ is the correlation between X and Y in the population. 

Pearson's correlation measures the strength of the linear relationship between two variables. 
The relationship here is not linear. As age increases, hours slept decreases rapidly at first but then levels off.

Part5. Probability
Inferential statistics is built on the foundation of probability theory, and has been remarkably successful in guiding opinion about the conclusions to be drawn from data. 
One conception of probability is drawn from the idea of symmetrical outcomes.
Probabilities can also be thought of in terms of relative frequencies. 
For some purposes, probability is best thought of as subjective. 

Probability of a Single Event
If you roll a six-sided die, there are six possible outcomes, and each of these outcomes is equally likely.
The two outcomes about which we are concerned (a one or a six coming up) are called favorable outcomes. 
Given that all outcomes are equally likely, we can compute the probability of a one or a six using the formula:

probability  = Number of favorable outcomes / Number of possible equally-likely outcomes

Probability of Two (or more) Independent Events
Events A and B are independent events if the probability of Event B occurring is the same whether or not Event A occurs.

Probability of A and B
When two events are independent, the probability of both occurring is the product of the probabilities of the individual events. 
More formally, if events A and B are independent, then the probability of both A and B occurring is:
P(A and B) = P(A) x P(B)

Probability of A or B
If Events A and B are independent, the probability that either Event A or Event B occurs is:
P(A or B) = P(A) + P(B) - P(A and B)

In this discussion, when we say "A or B occurs" we include three possibilities:
1. A occurs and B does not occur
2. B occurs and A does not occur
3. Both A and B occur

Conditional Probabilities
Often it is required to compute the probability of an event given that another event has occurred. 

Permutations and Combinations

Possible Orders
The formula for the number of orders is shown below.
Number of orders = n!

Multiplication Rule
Imagine a small restaurant whose menu has 3 soups, 6 entrées, and 4 desserts. 
How many possible meals are there? The answer is calculated by multiplying the numbers to get 3 x 6 x 4 = 72. 

Permutations
Suppose that there were four pieces of candy (red, yellow, green, and brown) and you were only going to pick up exactly two pieces. How many ways are there of picking up two pieces?

More formally, this question is asking for the number of permutations of four things taken two at a time. The general formula is:

nPr = n!/(n-r)!
nPr is the number of permutations of n things taken r at a time. In other words, it is the number of ways r things can be selected from a group of n things. 
It is important to note that order counts in permutations.
Therefore permutations refer to the number of ways of choosing rather than the number of possible outcomes. 
When order of choice is not considered, the formula for combinations is used.

Combinations

The formula for the number of combinations is shown below where nCr is the number of combinations for n things taken r at a time.
nCr = n!/(n-r)!r!

Binomial Distribution
we consider probability distributions for which there are just two possible outcomes with fixed probabilities summing to one. These distributions are called binomial distributions.

The Formula for Binomial Probabilities
The binomial distribution consists of the probabilities of each of the possible numbers of successes on N trials for independent events that each have a probability of π (the Greek letter pi) of occurring.

P(x) = N!/x!(N-x)! * (π)power(x) * (1-π)power(N-x)
P(x) = NCx * (π)power(x) * (1-π)power(N-x)

We toss a coin 12 times. What is the probability that we get from 0 to 3 heads? 
The answer is found by computing the probability of exactly 0 heads, exactly 1 head, exactly 2 heads, and exactly 3 heads. 
The probability of getting from 0 to 3 heads is then the sum of these probabilities.

Mean and Standard Deviation of Binomial Distributions
In general, the mean of a binomial distribution with parameters N (the number of trials) and π (the probability of success on each trial) is:
µ = Nπ

where μ is the mean of the binomial distribution. The variance of the binomial distribution is:
σ2 = Nπ(1-π)
σ2 is the variance of the binomial distribution.

Naturally, the standard deviation (σ) is the square root of the variance (σ2).
σ = sqrt(Nπ(1-π))

The binomial distribution is symmetric for p = 0.5.

 binomial distributions has the largest skew
The larger the difference between p and 0.5 and the smaller the N, the larger the skew

Poisson Distribution
The Poisson distribution can be used to calculate the probabilities of various numbers of "successes" based on the mean number of successes. 
In order to apply the Poisson distribution, the various events must be independent. 

Suppose you knew that the mean number of calls to a fire station on a weekday is 8. What is the probability that on a given weekday there would be 11 calls? This problem can be solved using the following formula based on the Poisson distribution:
poisson formula where

p = exp(-µ) * (µ)power(x) / x!

e is the base of natural logarithms (2.7183)
μ is the mean number of "successes"
x is the number of "successes" in question

The mean of the Poisson distribution is μ. The variance is also equal to μ. 

Multinomial Distribution
The binomial distribution allows one to compute the probability of obtaining a given number of binary outcomes. 
The multinomial distribution can be used to compute the probabilities in situations in which there are more than two possible outcomes. 

For example, suppose that two chess players had played numerous games and it was determined that the probability that Player A would win is 0.40, the probability that Player B would win is 0.35, and the probability that the game would end in a draw is 0.25. 
The multinomial distribution can be used to answer questions such as: "If these two chess players played 12 games, what is the probability that Player A would win 7 games, Player B would win 2 games, and the remaining 3 games would be drawn?" 
The following formula gives the probability of obtaining a specific set of outcomes when there are three possible outcomes for each event:

p= (n! / (n1!) * (n2!) *(n3!)) * p1**n1 * p2**n2 * p3**n3

p is the probability,
n is the total number of events
n1 is the number of times Outcome 1 occurs,
n2 is the number of times Outcome 2 occurs,
n3 is the number of times Outcome 3 occurs,
p1 is the probability of Outcome 1
p2 is the probability of Outcome 2, and
p3 is the probability of Outcome 3.

Hypergeometric Distribution
The hypergeometric distribution is used to calculate probabilities when sampling without replacement. 


For example, suppose you first randomly sample one card from a deck of 52. Then, without putting the card back in the deck you sample a second and then (again without replacing cards) a third. Given this sampling procedure, what is the probability that exactly two of the sampled cards will be aces (4 of the 52 cards in the deck are aces). You can calculate this probability using the following formula based on the hypergeometric distribution:
formula where

p = kCx * (N-K)C(n-x) / NCn

k is the number of "successes" in the population
x is the number of "successes" in the sample
N is the size of the population
n is the number sampled
p is the probability of obtaining exactly x successes
kCx is the number of combinations of k things taken x at a time

The mean and standard deviation of the hypergeometric distribution are:
µ = (n)(k)/N

sd = sqrt((n)(k)/N * (N-n)(N-k)/(N)(N-1))


Base Rates
For one thing, more information about the accuracy of the test is needed because there are two kinds of errors the test can make: misses and false positives. 

Miss
Misses occur when a diagnostic test returns a negative result, but the true state of the subject is positive. 
For example, if a person has strep throat and the diagnostic test fails to indicate it, then a miss has occurred. 
The concept is similar to a Type II error in significance testing.

False Positive
A false positive occurs when a diagnostic procedure returns a positive result while the true state of the subject is negative. 
For example, if a test for strep says the patient has strep when in fact he or she does not, then the error in diagnosis would be called a false positive. 
In some contexts, a false positive is called a false alarm. The concept is similar to a Type I error in significance testing.

The miss and false positive rates are not necessarily the same. 
For example, suppose that the test accurately indicates the disease in 99% of the people who have it and accurately indicates no disease in 91% of the people who do not have it. 
In other words, the test has a miss rate of 0.01 and a false positive rate of 0.09. This might lead you to revise your judgment and conclude that your chance of having the disease is 0.91.
This would not be correct since the probability depends on the proportion of people having the disease. This proportion is called the base rate.

Base Rate
The true proportion of a population having some condition, attribute or disease. 
For example, the proportion of people with schizophrenia is about 0.01. 
It is very important to consider the base rate when classifying people. 
As the saying goes, "if you hear hoofs, think horse not zebra" since you are more likely to encounter a horse than a zebra (at least in most places.)

Assume that Disease X is a rare disease, and only 2% of people in your situation have it.
How does that affect the probability that you have it? Or, more generally, what is the probability that someone who tests positive actually has the disease? 
Let's consider what would happen if one million people were tested. Out of these one million people, 2% or 20,000 people would have the disease. 
Of these 20,000 with the disease, the test would accurately detect it in 99% of them. This means that 19,800 cases would be accurately identified. 
Now let's consider the 98% of the one million people (980,000) who do not have the disease. Since the false positive rate is 0.09, 9% of these 980,000 people will test positive for the disease. 
This is a total of 88,200 people incorrectly diagnosed.
To sum up, 19,800 people who tested positive would actually have the disease and 88,200 people who tested positive would not have the disease. 
This means that of all those who tested positive, only   
19,800/(19,800 + 88,200) = 0.1833
of them would actually have the disease. So the probability that you have the disease is not 0.95, or 0.91, but only 0.1833.

			True Condition
No Disease  					Disease
980,000 						20,000
Test Result    			Test Result  
Positive  Negative       Positive  Negative  
88,200    891,800        19,800   200

sensitivity = TP/TP+FN = 19800/(891800 + 200)
specificity = TN/N = 891800/980000
precision = TP/TP+FP = 19800/ (19800 + 88200)
negative predictive = TN/TN+FN =  891800/( 891800+200)
accuracy = TP+TN/P+N = (891800 + 19800) / (980000+20000)
F1 = 2TP / (2TP + FP + FN)

Bayes' Theorem
This same result can be obtained using Bayes' theorem. 
Bayes' theorem considers both the prior probability of an event and the diagnostic value of a test to determine the posterior probability of the event.

Prior Probability
The prior probability of an event is the probability of the event computed before the collection of new data. 
One begins with a prior probability of an event and revises it in the light of new data. 

Posterior Probability
The posterior probability of an event is the probability of the event computed following the collection of new data.

For the current example, the event is that you have Disease X. Let's call this Event D. 
Since only 2% of people in your situation have Disease X, the prior probability of Event D is 0.02. Or, more formally, P(D) = 0.02. 
If P(D') represents the probability that Event D is false, then P(D') = 1 - P(D) = 0.98.

To define the diagnostic value of the test, we need to define another event: that you test positive for Disease X. Let's call this Event T. 
The diagnostic value of the test depends on the probability you will test positive given that you actually have the disease, written as P(T|D), 
and the probability you test positive given that you do not have the disease, written as P(T|D'). 
Bayes' theorem shown below allows you to calculate P(D|T), the probability that you have the disease given that you test positive for it.

P(D|T) = P(T|D)P(D)/(P(T|D)P(D) + P(T|D')P(D'))
P(D|T)P(T) = P(T|D)P(D)



Part6. Research Design

Scientific Method
Scientific theories must be potentially disconfirmable. If a theory can accommodate all possible results then it is not a scientific theory. 
Therefore, a scientific theory should lead to testable hypotheses. If a hypothesis is disconfirmed, then the theory from which the hypothesis was deduced is incorrect. 

Scientific theories must be potentially disconfirmable. If a theory can accommodate all possible results then it is not a scientific theory.
Therefore, a scientific theory should lead to testable hypotheses. If a hypothesis is disconfirmed, then the theory from which the hypothesis was deduced is incorrect.

If a hypothesis derived from a theory is confirmed then the theory has survived a test and it becomes more useful and better thought of by the researchers in the field.
A theory is not confirmed when correct hypotheses are derived from it.

A key difference between scientific explanations and faith-based explanations is simply that faith-based explanations are based on faith and do not need to be testable. 
This does not mean that an explanation that cannot be tested is incorrect in some cosmic sense. It just means that it is not a scientific explanation.

An important attribute of a good scientific theory is that it is parsimonious. 
That is, that it is simple in the sense that it uses relatively few constructs to explain many empirical findings.
A theory that it so complex that it has as many assumptions as it has predictions is not very valuable.

Although strictly speaking, disconfirming an hypothesis deduced from a theory disconfirms the theory, it rarely leads to the abandonment of the theory. 
Instead, the theory will probably be modified to accommodate the inconsistent finding. 
If the theory has to be modified over and over to accommodate new findings, the theory generally becomes less and less parsimonious. 
This can lead to discontent with the theory and the search for a new theory. 
If a new theory is developed that can explain the same facts in a more parsimonious way, then the new theory will eventually supercede the old theory.

Simpler explanations are preferred over complex explanations so theories should be parsimonious.

Measurement

Reliability
The notion of reliability revolves around whether you would get at least approximately the same result if you measure something twice with the same measurement instrument. 
A common way to define reliability is the correlation between parallel forms of a test. 
Letting "test" represent a parallel form of the test, the symbol rtest,test is used to denote the reliability of the test.

True Scores and Error
The mean response time over the 1,000 trials can be thought of as the person's "true" score, or at least a very good approximation of it. 
Theoretically, the true score is the mean that would be approached as the number of trials increases indefinitely.

Every test score can be thought of as the sum of two independent components, the true score and the error score. This can be written as:
Ytest = Ytrue + Yerror
The following expression follows directly from the Variance Sum Law:
Var(test) = Var(true) + Var(error)

Reliability in Terms of True Scores and Error
It can be shown that the reliability of a test, rtest,test, is the ratio of true-score variance to test-score variance. This can be written as:

rtest, test = Var(true)/Var(test) = Var(true)/[Var(true) + Var(error)]

If a test were given in two populations for which the variance of the true scores differed, the reliability of the test would be higher in the population with the higher true-score variance. 
Therefore, reliability is not a property of a test per se but the reliability of a test in a given population.

Assessing Error of Measurement
The reliability of a test does not show directly how close the test scores are to the true scores. 
That is, it does not reveal how much a person's test score would vary across parallel forms of test.

By definition, the mean over a large number of parallel tests would be the true score. 
The standard deviation of a person's test scores would indicate how much the test scores vary from the true score. 
This standard deviation is called the standard error of measurement. 

The following formula is used to estimate the standard error of measurement.
formula for standard error of measurement:
 
Smeasurement = Stest*sqrt(1-rtest,tes)

where Smeasurement is the standard error of measurement, Stest is the standard deviation of the test scores, and rtest,test is the reliability of the test.
Taking the extremes, if the reliability is 0 then the standard error of measurement is equal to the standard deviation of the test; if the reliability is perfect (1.0) then the standard error of measurement is 0.
 
Increasing Reliability
The higher the reliability of the test of spatial ability, the higher the correlations will be. 
Similarly, if an experimenter seeks to determine whether a particular exercise regiment decreases blood pressure, the higher the reliability of the measure of blood pressure, the more sensitive the experiment. 

Two basic ways of increasing reliability are 
(1) to improve the quality of the items and 
(2) to increase the number of items.

Increasing the number of items increases reliability in the manner shown by the following formula:

rnew,new = k*rtest,test/(1+(k-1)rtest,test)

where k is the factor by which the test length is increased, 
rnew,new is the reliability of the new longer test, and rtest,test is the current reliability. 

For example, if a test with 50 items has a reliability of .70 then the reliability of a test that is 1.5 times longer (75 items) would be calculated as follows
rnew,new = 1.5*.7/(1+(1.5-1)*.7) = .78

It is important to note that this formula assumes the new items have the same characteristics as the old items. 
Obviously adding poor items would not increase the reliability as expected and might even decrease the reliability.

Validity
The validity of a test refers to whether the test measures what it is supposed to measure.
The three most common types of validity are face validity, empirical validity, and construct validity. 

Face Validity
A test's face validity refers to whether the test appears to measure what it is supposed to measure.

Predictive Validity
Predictive validity (sometimes called empirical validity) refers to a test's ability to predict the relevant behavior.


Construct Validity
Construct validity is more difficult to define. In general, a test has construct validity if its pattern of correlations with other measures is in line with the construct it is purporting to measure. 
Construct validity can be established by showing a test has both convergent and divergent validity. 
A test has convergent validity if it correlates with other tests that are also measures of the construct in question. 
Divergent validity is established by showing the test does not correlate highly with tests of other constructs. 
Of course, some constructs may overlap so the establishment of convergent and divergent validity can be complex.

To take an example, suppose one wished to establish the construct validity of a new test of spatial ability. 
Convergent and divergent validity could be established by showing the test correlates relatively highly with other measures of spatial ability but less highly with tests of verbal ability or social intelligence.

Reliability and Predictive Validity
The reliability of a test limits the size of the correlation between the test and other measures. 
In general, the correlation of a test with another measure will be lower than the test's reliability. 
After all, how could a test correlate with something else as high as it correlates with a parallel form of itself? 
Theoretically it is possible for a test to correlate as high as the square root of the reliability with another measure. 
For example, if a test has a reliability of 0.81 then it could correlate as high as 0.90 with another measure. 
This could happen if the other measure were a perfectly reliable test of the same construct as the test in question. 
In practice, this is very unlikely.

A true score 

 (a) is a measurement without error.

 (b) is approached as the number of items in a test increases.
 
If a test has a reliability of .64 then the theoretical upper limit on its predictive validity is 0.8 reason:
The upper limit is the square root of the reliability. It is rare but theoretically possible for the validity to be higher than the reliability.


Part7. Normal Distribution

The normal distribution is the most important and most widely used distribution in statistics. 
It is sometimes called the "bell curve," although the tonal qualities of such a bell would be less than pleasing. It is also called the "Gaussian curve" after the mathematician Karl Friedrich Gauss.

1. Normal distributions are symmetric around their mean.
2. The mean, median, and mode of a normal distribution are equal.
3. The area under the normal curve is equal to 1.0.
4. Normal distributions are denser in the center and less dense in the tails.
5. Normal distributions are defined by two parameters, the mean (μ) and the standard deviation (σ).
6. 68% of the area of a normal distribution is within one standard deviation of the mean.
7. Approximately 95% of the area of a normal distribution is within two standard deviations of the mean.
 

The normal distributions shown in Figures 1 and 2 are specific examples of the general rule that 68% of the area of any normal distribution is within one standard deviation of the mean.
The shaded area contains 95% of the area and extends from 55.4 to 94.6. For all normal distributions, 95% of the area is within 1.96 standard deviations of the mean. 
68% of the area is within 1 standard deviation of the mean

The probability of any one specific point is 0. 
The problem is that the binomial distribution is a discrete probability distribution, whereas the normal distribution is a continuous distribution.

The normal approximation to the binomial is most accurate for which of the following probabilities?
It is most accurate for p=.5 because that makes the binomial distribution symmetric and closer to a normal distribution.

The normal approximation to the binomial is most accurate for which of the following sample sizes?
The binomial distribution approaches a normal distribution as the sample size increases. Therefore the approximation is best when the sample size is highest.

Because the normal distribution is continuous, the probability of any one specific point is 0. 
The solution is to round off and consider any value from 5.5 to 6.5 to represent an outcome of 6 tails. 
Using this approach, we figure out the area under a normal curve from 5.5 to 6.5.

Risk analyses often are based on the assumption of normal distributions. 
Critics have said that extreme events in reality are more frequent than would be expected assuming normality. 
The assumption has even been called a "Great Intellectual Fraud."

A recent article discussing how to protect investments against extreme events defined "tail risk" 
as "A tail risk, or extreme shock to financial markets, is technically defined as an investment that moves more than three standard deviations from the mean of a normal distribution of investment returns."

Tail risk can be evaluated by assuming a normal distribution and computing the probability of such an event. Is that how "tail risk" should be evaluated? 

Events more than three standard deviations from the mean are very rare for normal distributions. 
However, they are not as rare for other distributions such as highly-skewed distributions. 
If the normal distribution is used to assess the probability of tail events defined this way, then the "tail risk" will be underestimated.

Part. 9 Sampling Distribution

A sampling distribution can be thought of as a relative frequency distribution with a very large number of samples. 
More precisely, a relative frequency distribution approaches the sampling distribution as the number of samples approaches infinity. 
When a variable is discrete, the heights of the distribution are probabilities. 
When a variable is continuous, the class intervals have no width and and the heights of the distribution are probability densities.

The distribution shown in Figure 2 is called the sampling distribution of the mean. 
Specifically, it is the sampling distribution of the mean for a sample size of 2 (N = 2)

Notice that all the means are either 1.0, 1.5, 2.0, 2.5, or 3.0. 
The frequencies of these means are shown in Table 2. 
The relative frequencies are equal to the frequencies divided by nine because there are nine possible outcomes.
Mean	Frequency	Relative Frequency
1.0	1	0.111
1.5	2	0.222
2.0	3	0.333
2.5	2	0.222
3.0	1	0.111


When we have a truly continuous distribution, it is not only impractical but actually impossible to enumerate all possible outcomes. 
Moreover, in continuous distributions, the probability of obtaining any single value is zero. 
Therefore, as discussed in the section "Introduction to Distributions," these values are called probability densities rather than probabilities.

The most common measure of how much sample means differ from each other is the standard deviation of the sampling distribution of the mean. 
This standard deviation is called the standard error of the mean. 
If all the sample means were very close to the population mean, then the standard error of the mean would be small. 
On the other hand, if the sample means varied considerably, then the standard error of the mean would be large.

Keep in mind that all statistics have sampling distributions, not just the mean. 
In later sections we will be discussing the sampling distribution of the variance, 
the sampling distribution of the difference between means, 
and the sampling distribution of Pearson's correlation, among others.

The sampling distribution is a theoretical distribution that is approached as the number of samples approaches infinity.
Every statis has its own sampling distribution.
There is a different sampling distribution for different parent population and for different sample sizes.

Sample size is the number of original data points included in a single sample.
Because the student performs the sampling process 500 times, the number of samples included in the estimation of the sampling distribution is 500.

The mean of the sampling distribution of the range is less than the range in the population. 
The range in the population is the largest possible range for a sample. The mean range in a sample will be less than this.

Sample size affects the spread (variability) of the distriubtion of sample means. 
The smaller the sample size, the more spread out the distribution. 
Therefore, the mean of a small sample size is more likely to deviate greatly from the mean value of 16. In this situation, much more likely.

Central Limit Theorem
Although counter-intuitive, the sampling distribution of the mean approaches a normal distribution as sample size increases. 
This is an important part of the "Central Limit Theorem."

The variance of the sampling distribution of the mean is proportional to the sample size. 
Therefore, the variance will be one fifth as large and will equal 5.

Mean
The mean of the sampling distribution of the mean is the mean of the population from which the scores were sampled. 
Therefore, if a population has a mean μ, then the mean of the sampling distribution of the mean is also μ. 
The symbol μM is used to refer to the mean of the sampling distribution of the mean. 
μM = μ

Variance
The variance of the sampling distribution of the mean is computed as follows:
σ2M = σ2/N

That is, the variance of the sampling distribution of the mean is the population variance divided by N, the sample size (the number of scores used to compute a mean).
Thus, the larger the sample size, the smaller the variance of the sampling distribution of the mean.

Central Limit Theorem
The central limit theorem states that:
Given a population with a finite mean μ and a finite non-zero variance σ2, 
the sampling distribution of the mean approaches a normal distribution with a mean of μ and a variance of σ2/N as N, the sample size, increases.

According to the central limit theorem, regardless of the shape of the parent population, the sampling distribution of the mean approaches a normal distribution as N increases. 


Sampling Distribution of Difference Between Means
The sampling distribution of the difference between means can be thought of as the distribution that would result if we repeated the following three steps over and over again: 
(1) sample n1 scores from Population 1 and n2 scores from Population 2, 
(2) compute the means of the two samples (M1 and M2), 
(3) compute the difference between means, M1 - M2. 
The distribution of the differences between means is the sampling distribution of the difference between means.

As you might expect, the mean of the sampling distribution of the difference between means is:
μM1-M2 = μM1-µM2

which says that the mean of the distribution of differences between sample means is equal to the difference between population means. 
The formula for the variance of the sampling distribution of the difference between means as:
σ2M1-M2 = σ21/N1 + σ22/N2

σM1- σM2 = sqrt(σ21/N1 + σ22/N2)

The mean height of 15-year-old boys is 175 cm and the variance is 64. 
For girls, the mean is 165 and the variance is 64. 
If 8 boys and 8 girls were sampled, what is the probability that the mean height of the sample of boys would be at least 6 cm higher than the mean height of the sample of girls?
mean = 175-165 = 10
sd = sqrt(2*64/8)=4
Z = (6-10)/4 = -1
P(x>=-1) = 1-P(x<-1) 
in python :
import scipy.stats
1- scipy.stats.norm(0,1).cdf(-1) = 0.841
or 1- scipy.stats.norm(10,4).cdf(6) = 0.841

Sampling Distribution of Pearson's r
If 12 students were sampled randomly, the sample correlation, r, would not be exactly equal to 0.60. 
Naturally different samples of 12 students would yield different values of r. 
The distribution of values of r after repeated samples of 12 students is the sampling distribution of r.

You can see that the sampling distribution is not symmetric: it is negatively skewed. 
The reason for the skew is that r cannot take on values greater than 1.0 and therefore the distribution cannot extend as far in the positive direction as it can in the negative direction. 
The greater the value of ρ, the more pronounced the skew.

You might think that all you would need to know to compute this probability is the mean and standard error of the sampling distribution of r. 
However, since the sampling distribution is not normal, you would still not be able to solve the problem. 
Fortunately, the statistician Fisher developed a way to transform r to a variable that is normally distributed with a known standard error. 
The variable is called z' and the formula for the transformation is given below.

z' = 0.5*ln[(1+r)/(1-r)]

The details of the formula are not important here since normally you will use either a table or calculator to do the transformation.
What is important is that z' is normally distributed and has a standard error of
σ = 1/sqrt(N-3)
where N is the number of pairs of scores.

What is the shape of the sampling distribution of r? 
Unless r = 0, the sampling distribution is skewed. 
The reason for the skew is that r cannot take on values greater than 1.0 or less than -1.0, 
and therefore the distribution cannot extend as far in one direction as it can in the other. 

Although you could plug all of these values into the r to z' calculator, you don't need to do that. 
You know the r with the biggest absolute value has the most skewed sampling distribution, so it is the most different from its corresponding z'.

Sampling Distribution of p
Assume that in an election race between Candidate A and Candidate B, 0.60 of the voters prefer Candidate A. 
If a random sample of 10 voters were polled, it is unlikely that exactly 60% of them (6) would prefer Candidate A. 
By chance the proportion in the sample preferring Candidate A could easily be a little lower than 0.60 or a little higher than 0.60. 
The sampling distribution of p is the distribution that would result if you repeatedly sampled 10 voters and determined the proportion (p) that favored Candidate A.

The distribution of p is closely related to the binomial distribution. 
The binomial distribution is the distribution of the total number of successes (favoring Candidate A, for example) whereas the distribution of p is the distribution of the mean number of successes. 
The mean, of course, is the total divided by the sample size, N. 
Therefore, the sampling distribution of p and the binomial distribution differ in that p is the mean of the scores (0.70) and the binomial distribution is dealing with the total number of successes (7).
The binomial distribution has a mean of
μ = Nπ
Dividing by N to adjust for the fact that the sampling distribution of p is dealing with means instead of totals, we find that the mean of the sampling distribution of p is:
μp = π

The standard deviation of the binomial distribution is:
sqrt(Nπ(1-π))

Dividing by N because p is a mean not a total, we find the standard error of p:
1/N *(sqrt(Nπ(1-π))) = sqrt(π(1-π)/N)

The sampling distribution of p is a discrete rather than a continuous distribution.
The sampling distribution of p is approximately normally distributed if N is fairly large and π is not close to 0 or 1. 
A rule of thumb is that the approximation is good if both Nπ and N(1 - π) are greater than 10.

Part. 10 Estimation
Population
A population is the complete set of observations a researcher is interested in.
Contrast this with a sample which is a subset of a population.
A population can be defined in a manner convenient for a researcher.
Inferential statistics are computed from sample data in order to make inferences about the population.
Parameter
A value calculated in a population. For example, the mean of the numbers in a population is a parameter.
Compare with a statistic, which is a value computed in a sample to estimate a parameter.
point estimate: an estimate consists a signal point or value

Point estimates are usually supplemented by interval estimates called confidence intervals.
Confidence intervals are intervals constructed using a method that contains the population parameter a specified proportion of the time.

One of the major applications of statistics is estimating population parameters from sample statistics.

Degrees of Freedom
Some estimates are based on more information than others.
For example, an estimate of the variance based on a sample size of 100 is based on more information than an estimate of the variance based on a sample size of 5.
The degrees of freedom (df) of an estimate is the number of independent pieces of information on which the estimate is based.
 
As you are probably thinking, it is pretty rare that we know the population mean when we are estimating the variance. 
Instead, we have to first estimate the population mean (μ) with the sample mean (M). 
Returning to our problem of estimating the variance in Martian heights, let's assume we do not know the population mean and therefore we have to estimate it from the sample. 
We have sampled two Martians and found that their heights are 8 and 5. Therefore M, our estimate of the population mean, is
M = (8+5)/2 = 6.5.

We can now compute two estimates of variance:
Estimate 1 = (8-6.5)2 = 2.25
Estimate 2 = (5-6.5)2 = 2.25

Now for the key question: Are these two estimates independent? The answer is no because each height contributed to the calculation of M.
The important point is that the two estimates are not independent and therefore we do not have two degrees of freedom. 
Another way to think about the non-independence is to consider that if you knew the mean and one of the scores, you would know the other score. 

In general, the degrees of freedom for an estimate is equal to the number of values minus the number of parameters estimated en route to the estimate in question.
Therefore, the degrees of freedom of an estimate of variance is equal to N - 1, where N is the number of observations.
s2 = sum(X-M)2/(N-1)

Characteristics of Estimators
This section discusses two important characteristics of statistics used as point estimates of parameters: bias and sampling variability.
Bias refers to whether an estimator tends to either over or underestimate the parameter. 
Sampling variability refers to how much the estimate varies from sample to sample.

A statistic is biased if the long-term average value of the statistic is not the parameter it is estimating.
More formally, a statistic is biased if the mean of the sampling distribution of the statistic is not equal to the parameter.
The mean of the sampling distribution of a statistic is sometimes referred to as the expected value of the statistic.

As we saw in the section on the sampling distribution of the mean, the mean of the sampling distribution of the (sample) mean is the population mean (μ). 
Therefore the sample mean is an unbiased estimate of μ. 
Any given sample mean may underestimate or overestimate μ, but there is no systematic tendency for sample means to either under or overestimate μ.

if N is used in the formula for s2, then the estimates tend to be too low and therefore biased. 
The formula with N-1 in the denominator gives an unbiased estimate of the population variance. 
Note that N-1 is the degrees of freedom.

Sampling Variability
The sampling variability of a statistic refers to how much the statistic varies from sample to sample and is usually measured by its standard error ; 
the smaller the standard error, the less the sampling variability.

Statistics differ in their sampling variability even with the same sample size. 
For example, for normal distributions, the standard error of the median is larger than the standard error of the mean. 
The smaller the standard error of a statistic, the more efficient the statistic. 
The relative efficiency of two statistics is typically defined as the ratio of their standard errors.


Minimizing total model error relies on the balancing of bias and variance errors. 
Ideally, models are the result of a collection of unbiased data of low variance. 
Unfortunately, however, the more complex a model becomes, its tendency is toward less bias but greater variance; therefore an optimal model would need to consider a balance between these 2 properties.

The statistical evaluation method of cross-validation is useful in both demonstrating the importance of this balance, as well as actually searching it out. 
The number of data folds to use -- the value of k in k-fold cross-validation -- is an important decision; the lower the value, the higher the bias in the error estimates and the less variance.

Bias and variance contributing to total error, Image sourceConversely, when k is set equal to the number of instances, the error estimate is then very low in bias but has the possibility of high variance.
The most important takeaways are that bias and variance are two sides of an important trade-off when building models, and that even the most routine of statistical evaluation methods are directly reliant upon such a trade-off.

Confidence Intervals Introduction
A point estimate by itself is of limited usefulness because it does not reveal the uncertainty associated with the estimate; 
you do not have a good sense of how far this sample mean may be from the population mean. 
Confidence intervals provide more information than point estimates.  

Confidence intervals for means are intervals constructed using a procedure (presented in the next section) 
that will contain the population mean a specified proportion of the time, typically either 95% or 99% of the time. 
These intervals are referred to as 95% and 99% confidence intervals respectively. 

If repeated samples were taken and the 95% confidence interval computed for each sample, 95% of the intervals would contain the population mean. 
Naturally, 5% of the intervals would not contain the population mean.

Confidence Interval on the Mean

In general, you compute the 95% confidence interval for the mean with the following formula:
Lower limit = M - Z.95σM
Upper limit = M + Z.95σM

where Z.95 is the number of standard deviations extending from the mean of a normal distribution required to contain 0.95 of the area
and σM is the standard error of the mean.

If you look closely at this formula for a confidence interval, you will notice that you need to know the standard deviation (σ) in order to estimate the mean.
This may sound unrealistic, and it is. However, computing a confidence interval when σ is known is easier than when σ has to be estimated, and serves a pedagogical purpose.

When you compute a confidence interval on the mean, you compute the mean of a sample in order to estimate the mean of the population. 
Clearly, if you already knew the population mean, there would be no need for a confidence interval. 
You should use the t distribution rather than the normal distribution when the variance is not known and has to be estimated from sample data.

When the sample size is large, say 100 or above, the t distribution is very similar to the standard normal distribution.
However, with smaller sample sizes, the t distribution is leptokurtic, which means it has relatively more scores in its tails than does the normal distribution.

Assume that the following five numbers are sampled from a normal distribution: 2, 3, 5, 6, and 9 and that the standard deviation is not known. 
The first steps are to compute the sample mean and variance:

        M = 5
        s2 = 7.5
The next step is to estimate the standard error of the mean. If we knew the population variance, we could use the following formula:

σM = σ/sqrt(N) 
Instead we compute an estimate of the standard error (sM):
sM = s/sqrt(N)= 1.225

The next step is to find the value of t. As you can see from Table 1, the value for the 95% interval for df = N - 1 = 4 is 2.776.
The confidence interval is then computed just as it is when σM.
The only differences are that sM and t rather than σM and Z are used.

Lower limit = 5 - (2.776)(1.225) = 1.60
Upper limit = 5 + (2.776)(1.225) = 8.40


More generally, the formula for the 95% confidence interval on the mean is:
Lower limit = M - (tCL)(sM)
Upper limit = M + (tCL)(sM)

where M is the sample mean, tCL is the t for the confidence level desired (0.95 in the above example),
and sM is the estimated standard error of the mean.

t Distribution
Intuitively, it makes sense that the probability of being within 1.96 standard errors of the mean should be smaller than in the case when the standard deviation is known (and cannot be underestimated).
But exactly how much smaller? Fortunately, the way to work out this type of problem was solved in the early 20th century by W. S. Gosset
who determined the distribution of a mean divided by an estimate of its standard error.

he t distribution is very similar to the normal distribution when the estimate of variance is based on many degrees of freedom, but has relatively more scores in its tails when there are fewer degrees of freedom.
Since the t distribution is leptokurtic, the percentage of the distribution within 1.96 standard deviations of the mean is less than the 95% for the normal distribution.

Difference between Means
It is much more common for a researcher to be interested in the difference between means than in the specific values of the means themselves. 

Difference between Means

In order to construct a confidence interval, we are going to make three assumptions:

1. The two populations have the same variance. This assumption is called the assumption of homogeneity of variance.
2. The populations are normally distributed.
3. Each value is sampled independently from each other value.

A confidence interval on the difference between means is computed using the following formula:
Lower Limit = M1 - M2 -(tCL)(Sm1-m2)
Upper Limit = M1 - M2 +(tCL)(Sm1-m2)

where M1 - M2 is the difference between sample means, tCL is the t for the desired level of confidence, and  is the estimated standard error of the difference between sample means. 

The first step is to compute the estimate of the standard error of the difference between means (Sm1-m2).

In order to estimate this quantity, we estimate σ2 and use that estimate in place of σ2. 
Since we are assuming the population variances are the same, we estimate this variance by averaging our two sample variances. 
Thus, our estimate of variance is computed using the following formula:
MSE = ((S1)2 + (S2)2)/2

where MSE is our estimate of σ2. 
Note that MSE stands for "mean square error" and is the mean squared deviation of each score from its group's mean.

Sm1-m2 = sqrt(MSE/N)

The next step is to find the t to use for the confidence interval (tCL). 
To calculate tCL, we need to know the degrees of freedom. 
The degrees of freedom is the number of independent estimates of variance on which MSE is based. 
This is equal to (n1 - 1) + (n2 - 1) where n1 is the sample size of the first group and n2 is the sample size of the second group. 

Computations for Unequal Sample Sizes (optional)

The calculations are somewhat more complicated when the sample sizes are not equal. 
One consideration is that MSE, the estimate of variance, counts the sample with the larger sample size more than the sample with the smaller sample size. 
Computationally this is done by computing the sum of squares error (SSE) as follows:

SSE = sum(X-M1)2 + sum(X-M2)2
where M1 is the mean for group 1 and M2 is the mean for group 2.

Then, MSE is computed by: MSE = SSE/df

The formula Sm1-m2 = sqrt(MSE/N)
is replaced by

Sm1-m2 = sqrt(MSE/Nh)

Nh is the harmonic mean of the sample size and is computed as follows:
Nh = 2/ ((1/n1)+ (1/n2))

Correlation

The steps in computing a confidence interval for ρ are:
1. Convert r to z'
2. Compute a confidence interval in terms of z'
3. Convert the confidence interval back to r.

Proportion
Although this point estimate of the proportion is informative, it is important to also compute a confidence interval. 
The confidence interval is computed based on the mean and standard deviation of the sampling distribution of a proportion. 
µp = π
σp = sqrt(π(1-π)/N)

Since we do not know the population parameter π, we use the sample proportion p as an estimate. The estimated standard error of p is therefore
sp = sqrt(p(1-p)/N)

We start by taking our statistic (p) and creating an interval that ranges (Z.95)(sp) in both directions, 
where Z.95 is the number of standard deviations extending from the mean of a normal distribution required to contain 0.95 of the area.

The value of Z.95 is computed with the normal calculator and is equal to 1.96. 
We then make a slight adjustment to correct for the fact that the distribution is discrete rather than continuous.

To correct for the fact that we are approximating a discrete distribution with a continuous distribution (the normal distribution), 
we subtract 0.5/N from the lower limit and add 0.5/N to the upper limit of the interval. 

Margin of Error

When a statistic is used to estimate a parameter, it is common to compute a confidence interval. 
The margin of error is the difference between the statistic and the endpoints of the interval. 
For example, if the statistic were 0.6 and the confidence interval ranged from 0.4 to 0.8, then the margin of error would be 0.20. 
Unless otherwise specified, the 95% confidence interval is used.

Keep in mind that the margin of error of 4.5% is the margin of error for the percent favoring the candidate 
and not the margin of error for the difference between the percent favoring the candidate and the percent favoring the opponent. 
The margin of error for the difference is 9%, twice the margin of error for the individual percent.

Part11. Logic of Hypothesis Testing
Random assignment of charts does not ensure that the groups will be equal in all respects other than the chart they viewed. 
In fact, it is certain the two groups differed in many ways by chance.

The Probability Value

The probability of 0.0106 is the probability of a certain outcome (13 or more out of 16) assuming a certain state of the world (James Bond was only guessing). 
It is not the probability that a state of the world is true.

To reiterate, the probability value is the probability of an outcome (9/16 or better) and not the probability of a particular state of the world (the bird was only guessing).

In statistics, it is conventional to refer to possible states of the world as hypotheses since they are hypothesized states of the world. 
Using this terminology, the probability value is the probability of an outcome given the hypothesis. It is not the probability of the hypothesis given the outcome.

This is not to say that we ignore the probability of the hypothesis. 
If the probability of the outcome given the hypothesis is sufficiently low, we have evidence that the hypothesis is false. 
However, we do not compute the probability that the hypothesis is false. 

The Null Hypothesis
The hypothesis that an apparent effect is due to chance is called the null hypothesis. 

Although the null hypothesis is usually that the value of a parameter is 0, there are occasions in which the null hypothesis is a value other than 0. 
For example, if one were testing whether a subject differed from chance in their ability to determine whether a flipped coin would come up heads or tails, the null hypothesis would be that π = 0.5.

Significance Testing
It is conventional to conclude the null hypothesis is false if the probability value is less than 0.05. 
More conservative researchers conclude the null hypothesis is false only if the probability value is less than 0.01. 

The probability value below which the null hypothesis is rejected is called the α (alpha) level or simply α. It is also called the significance level.

When the null hypothesis is rejected, the effect is said to be statistically significant. 

For example, in the Physicians' Reactions case study, the probability value is 0.0057. 
Therefore, the effect of obesity is statistically significant and the null hypothesis that obesity makes no difference is rejected. 

It is very important to keep in mind that statistical significance means only that the null hypothesis of exactly no effect is rejected; it does not mean that the effect is important, which is what "significant" usually means. 
When an effect is significant, you can have confidence the effect is not exactly zero. Finding that an effect is significant does not tell you about how large or important the effect is.

Do not confuse statistical significance with practical significance. A small effect can be highly significant if the sample size is large enough.

There are two approaches (at least) to conducting significance tests. 
In one (favored by R. Fisher), a significance test is conducted and the probability value reflects the strength of the evidence against the null hypothesis. 
If the probability is below 0.01, the data provide strong evidence that the null hypothesis is false. 
If the probability value is below 0.05 but larger than 0.01, then the null hypothesis is typically rejected, but not with as much confidence as it would be if the probability value were below 0.01. 
Probability values between 0.05 and 0.10 provide weak evidence against the null hypothesis and, by convention, are not considered low enough to justify rejecting it. 
Higher probabilities provide less evidence that the null hypothesis is false.

The alternative approach (favored by the statisticians Neyman and Pearson) is to specify an α level before analyzing the data. 
If the data analysis results in a probability value below the α level, then the null hypothesis is rejected; 
if it is not, then the null hypothesis is not rejected. 
According to this perspective, if a result is significant, then it does not matter how significant it is. 
Moreover, if it is not significant, then it does not matter how close to being significant it is. 
Therefore, if the 0.05 level is being used, then probability values of 0.049 and 0.001 are treated identically. 
Similarly, probability values of 0.06 and 0.34 are treated identically.

Type I and Type II Errors
Despite the low probability value, it is possible that the null hypothesis of no true difference between obese and average-weight patients is true and that the large difference between sample means occurred by chance. 
If this is the case, then the conclusion that physicians intend to spend less time with obese patients is in error. 
This type of error is called a Type I error.

More generally, a Type I error occurs when a significance test results in the rejection of a true null hypothesis.

As discussed in the section on significance testing, it is better to interpret the probability value as an indication of the weight of evidence against the null hypothesis 
than as part of a decision rule for making a reject or do-not-reject decision. 
Therefore, keep in mind that rejecting the null hypothesis is not an all-or-nothing decision.

The Type I error rate is affected by the α level: the lower the α level, the lower the Type I error rate. 
It might seem that α is the probability of a Type I error. 
However, this is not correct. Instead, α is the probability of a Type I error given that the null hypothesis is true. 
If the null hypothesis is false, then it is impossible to make a Type I error.

The second type of error that can be made in significance testing is failing to reject a false null hypothesis. 
This kind of error is called a Type II error. 

Unlike a Type I error, a Type II error is not really an error. 
When a statistical test is not significant, it means that the data do not provide strong evidence that the null hypothesis is false. 
Lack of significance does not support the conclusion that the null hypothesis is true. 
Therefore, a researcher should not make the mistake of incorrectly concluding that the null hypothesis is true when a statistical test was not significant. 
Instead, the researcher should consider the test inconclusive. 
Contrast this with a Type I error in which the researcher erroneously concludes that the null hypothesis is false when, in fact, it is true.

A Type II error can only occur if the null hypothesis is false. 
If the null hypothesis is false, then the probability of a Type II error is called β (beta). 
The probability of correctly rejecting a false null hypothesis equals 1- β and is called power.

One- and Two-Tailed Tests

Two-tailed tests are much more common than one-tailed tests in scientific research because an outcome signifying that something other than chance is operating is usually worth noting. 
One-tailed tests are appropriate when it is not important to distinguish between no effect and an effect in the unexpected direction. 

Steps in Hypothesis Testing
1. The first step is to specify the null hypothesis. For a two-tailed test, the null hypothesis is typically that a parameter equals zero although there are exceptions. 
For a one-tailed test, the null hypothesis is either that a parameter is greater than or equal to zero or that a parameter is less than or equal to zero. 

2. The second step is to specify the α level which is also known as the significance level. Typical values are 0.05 and 0.01. 

3. The third step is to compute the probability value (also known as the p value). 
This is the probability of obtaining a sample statistic as different or more different from the parameter specified in the null hypothesis given that the null hypothesis is true.

4. Finally, compare the probability value with the α level. 
If the probability value is lower then you reject the null hypothesis. 
 Keep in mind that rejecting the null hypothesis is not an all-or-none decision. 
 The lower the probability value, the more confidence you can have that the null hypothesis is false. 
 However, if your probability value is higher than the conventional α level of 0.05, most scientists will consider your findings inconclusive. 
 Failure to reject the null hypothesis does not constitute support for the null hypothesis. It just means you do not have sufficiently strong data to reject it.
 
 Significance Testing and Confidence Intervals
 Whenever an effect is significant, all values in the confidence interval will be on the same side of zero (either all positive or all negative). 
 Therefore, a significant finding allows the researcher to specify the direction of the effect. 
 
 If the 95% confidence interval contains zero (more precisely, the parameter value specified in the null hypothesis), then the effect will not be significant at the 0.05 level.
 
 
Part.12 Tests of Means

Testing a Single Mean
This section shows how to test the null hypothesis that the population mean is equal to some hypothesized value.
The significance test consists of computing the probability of a sample mean differing from μ by one (the difference between the hypothesized population mean and the sample mean) or more.
Difference between a sample mean and a specific value 

we compute t using a special case of the following formula:
t = (statistic - hypothesizd value)/estimated standard error of the statistic

t  = (M-µ)/sM
where t is the value we compute for the significance test, M is the sample mean, μ is the hypothesized value of the population mean, and sM is the estimated standard error of the mean.

Difference between Two Means (Independent Groups)
This section covers how to test for differences between means from two separate groups of subjects. 
What is important is whether there is a difference in the population means.

In order to test whether there is a difference between population means, we are going to make three assumptions:
1. The two populations have the same variance. This assumption is called the assumption of homogeneity of variance.
2. The populations are normally distributed.
3. Each value is sampled independently from each other value. This assumption requires that each subject provide only one value. 
If a subject provides two scores, then the scores are not independent. The analysis of data with two scores per subject is shown in the section on the correlated t test later in this chapter.

between two groups, with the same sample number:

MSE = 1/2(s1^2+s2^2)
standard error = sqrt(2*MSE/N)

between two groups, with different sample numbers:

MSE = SSE/df
SSE: sum of squares error 
SSE = sum(X-M1)^2 + sum(X-M2)^2
Nh = 2/(1/N1 + 1/N2)

standars error = sqrt(2*MSE/Nh)

A test is robust to violations of its assumptions if the test is only slightly affected by these violations.


All Pairwise Comparisons Among Means
Problem: The more means that are compared, the more the Type I error rate is inflated. 
Solution:
Tukey Honestly Significant Difference test, Tukey test, Tukey HSD
Studentized Range Distribution

to calcule the significant value: 
Q = (Mi-Mj)/sqrt(MSE/n)
degree of freedom
number of groups



Specific Comparisons (Independent Groups)
This section shows how to test these more complex comparisons. 
The methods in this section assume that the comparison among means was decided on before looking at the data. 
Therefore these comparisons are called planned comparisons.
We call the value "L" for "linear combination."
L=sum(ciMi)
t = L/sqrt(sum(ci)^2MSE/n)

In a later chapter on Analysis of Variance, you will see that comparisons such as this are testing what is called an interaction. 
In general, there is an interaction when the effect of one variable differs as a function of the level of another variable. 

Multiple Comparisons
The more comparisons you make, the greater your chance of a Type I error. 
It is useful to distinguish between two error rates: (1) the per-comparison error rate and (2) the familywise error rate. 
The per-comparison error rate is the probability of a Type I error for a particular comparison. 
The familywise error rate is the probability of making one or more Type I errors in a family or set of comparisons. 

Fortunately, there is a simple approximation that is fairly accurate when the number of comparisons is small. 
Defining α as the per-comparison error rate and c as the number of comparisons, the following inequality always holds true for the familywise error rate (FW):
FW <=cα
This inequality is called the Bonferroni inequality.

The Bonferroni inequality can be used to control the familywise error rate as follows: If you want the familywise error rate to be α, you use α/c as the per-comparison error rate. 
This correction, called the Bonferroni correction, will generally result in a familywise error rate less than α.

The disadvantage of controlling the familywise error rate is that it makes it more difficult to obtain a significant result for any given comparison: 
The more comparisons you do, the lower the per-comparison rate must be and therefore the harder it is to reach significance. 

Difference Between Two Means (Correlated Pairs)

How does the size of the correlation affect how much change scores vary?
The higher the correlation, the less change scores vary.

Specific Comparisons (Correlated Observations)
Pairwise Comparisons (Correlated Observations)
Bonferroni adjustments are necessary when making multiple comparisons because they keep the Type I error rate from being inflated.

Part.14 Regression
Partitioning the Sums of Squares

One useful aspect of regression is that it can divide the variation in Y into two parts: the variation of the predicted scores and the variation of the errors of prediction. 
The variation of Y is called the sum of squares Y and is defined as the sum of the squared deviations of Y from the mean of Y. In the population, the formula is

SSY = sum(Y-µy)^2 (deviation of criterion scores)
where SSY is the sum of squares Y, Y is an individual value of Y, and μy is the mean of Y.

SSY can be partitioned into two parts: the sum of squares predicted (SSY') and the sum of squares error (SSE). 
The sum of squares predicted is the sum of the squared deviations of the predicted scores from the mean predicted score.
The sum of squares error is the sum of the squared errors of prediction. 

SSY' = sum(Y'-µy')^2 (deviation of predicted scores)
SSE = sum(Y-Y')^2 (error)

SSY = SSY' +  SSE

The SSY is the total variation, the SSY' is the variation explained, and the SSE is the variation unexplained. Therefore, the proportion of variation explained can be computed as:
Proportion explained = SSY'/SSY

There is an important relationship between the proportion of variation explained and Pearson's correlation: r2 is the proportion of variation explained. 
Therefore, if r = 1, then, naturally, the proportion of variation explained is 1; if r = 0, then the proportion explained is 0. 

Since the variance is computed by dividing the variation by N (for a population) or N-1 (for a sample), the relationships spelled out above in terms of variation also hold for variance. 

The degrees of freedom column (df) shows the degrees of freedom for each source of variation. 
The degrees of freedom for the sum of squares explained (SSY') is equal to the number of predictor variables (number of X).
The error degrees of freedom is equal to the total number of observations minus 2. (slope and intercept are estimated)
The total degrees of freedom is the total number of observations minus 1.   

Standard Error of the Estimate
The standard error of the estimate is a measure of the accuracy of predictions. 
Recall that the regression line is the line that minimizes the sum of squared deviations of prediction (also called the sum of squares error).
The standard error of the estimate is closely related to this quantity and is defined below:

σest = sqrt((sum(Y-Y')^2)/N)

where σest is the standard error of the estimate, Y is an actual score, Y' is a predicted score, and N is the number of pairs of scores. 
The numerator is the sum of squared differences between the actual scores and the predicted scores.

There is a version of the formula for the standard error in terms of Pearson's correlation:

σest = sqrt((1-ρ^2)SSY/N)

where ρ is the population value of Pearson's correlation and SSY is
SSY = sum(Y-µy)^2

Inferential Statistics for b and r
Although no assumptions were needed to determine the best-fitting straight line, assumptions are made in the calculation of inferential statistics.
Naturally, these assumptions refer to the population, not the sample.
1. Linearity: The relationship between the two variables is linear.
2. Homoscedasticity: The variance around the regression line is the same for all values of X.
3. The errors of prediction are distributed normally. 
	This means that the deviations from the regression line are normally distributed. It does not mean that X or Y is normally distributed.

Influential Observations
Influence
The influence of an observation can be thought of in terms of how much the predicted scores for other observations would differ if the observation in question were not included. 
Cook's D is a good measure of the influence of an observation and is proportional to the sum of the squared differences between predictions made with all observations in the analysis 
and predictions made leaving out the observation in question.

An observation's influence is a function of two factors: 
(1) how much the observation's value on the predictor variable differs from the mean of the predictor variable and 
(2) the difference between the predicted score for the observation and its actual score. 
The former factor is called the observation's leverage. The latter factor is called the observation's distance.

Leverage
The leverage of an observation is based on how much the observation's value on the predictor variable differs from the mean of the predictor variable. 
The greater an observation's leverage, the more potential it has to be an influential observation.
For example, an observation with a value equal to the mean on the predictor variable has no influence on the slope of the regression line regardless of its value on the criterion variable. 
On the other hand, an observation that is extreme on the predictor variable has the potential to affect the slope greatly.

Calculation of Leverage (h)
The first step is to standardize the predictor variable so that it has a mean of 0 and a standard deviation of 1. 
Then, the leverage (h) is computed by squaring the observation's value on the standardized predictor variable, adding 1, and dividing by the number of observations.

Xst = (X-Mx)/σx
h = Xst^2/N

Distance
The distance of an observation is based on the error of prediction for the observation: The greater the error of prediction, the greater the distance. 
The most commonly used measure of distance is the studentized residual. 
The studentized residual for an observation is closely related to the error of prediction for that observation divided by the standard deviation of the errors of prediction. 
However, the predicted score is derived from a regression equation in which the observation in question is not counted.

Regression Toward the Mean

Introduction to Multiple Regression 

It is difficult to compare the coefficients for different variables directly because they are measured on different scales. 
A difference of 1 in HSGPA is a fairly large difference, whereas a difference of 1 on the SAT is negligible. 
Therefore, it can be advantageous to transform the variables so that they are on the same scale. 
The most straightforward approach is to standardize the variables so that they each have a standard deviation of 1. 
A regression weight for standardized variables is called a "beta weight" and is designated by the Greek letter β. 
For these data, the beta weights are 0.625 and 0.198. 

Partitioning the Sums of Squares
SSY = SSY' + SSE
The sum of squares predicted is also referred to as the "sum of squares explained." 
Proportion Explained = SSY'/SSY

In simple regression, the proportion of variance explained is equal to r2; in multiple regression, the proportion of variance explained is equal to R2.

The sum of squares uniquely attributable to a variable is computed by comparing two regression models: the complete model and a reduced model. 
The complete model is the multiple regression with all the predictor variables included (HSGPA and SAT in this example). 
A reduced model is a model that leaves out one of the predictor variables. 
The sum of squares uniquely attributable to a variable is the sum of squares for the complete model minus the sum of squares for the reduced model in which the variable of interest is omitted.

When variables are highly correlated, the variance explained uniquely by the individual variables can be small even though the variance explained by the variables taken together is large.

Part15. Analysis of Variance
Analysis of Variance (ANOVA) is a statistical method used to test differences between two or more means.
ANOVA tests the non-specific null hypothesis that all four population means are equal.
This non-specific null hypothesis is sometimes called the omnibus null hypothesis. 

When the omnibus null hypothesis is rejected, the conclusion is that at least one population mean is different from at least one other mean.
However, since the ANOVA does not reveal which means are different from which, it offers less specific information than the Tukey HSD test.
The Tukey HSD is therefore preferable to ANOVA in this situation.

Factors and Levels
The section on variables defined an independent variable as a variable manipulated by the experimenter.
In describing an ANOVA design, the term factor is a synonym of independent variable.
Therefore, "Type of Smile" is the factor in this experiment.
Since four types of smiles were compared, the factor "Type of Smile" has four levels.

An ANOVA conducted on a design in which there is only one factor is called a one-way ANOVA.
If an experiment has two factors, then the ANOVA is called a two-way ANOVA.